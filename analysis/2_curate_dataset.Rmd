---
title: "Curate dataset"
date: "`r Sys.Date()`"
bibliography: references.bib
biblio-style: apalike
---

## About

### Description

The purpose of this script is to better organize the original data so that analyzing the dataset will be smoother and easier. In curating the dataset(s), we will be making changes to the original dataset, however these changes will be in the `data/derived/` folder instead.

### Usage

<!-- How to run this script: what input it requires and output produced -->

## Setup

```{r setup, include=FALSE}
# Script-specific options or packages
library(tidyverse) # data manipulation
library(readtext) # to read text into R
library(tidytext) # for tokenization/separating rows
```

## Run

```{r love_on_the_spectrum-idealized-dataset}
tribble(
  ~Series, ~Season, ~Episode,
  "Love on The Spectrum", "01", "01"
)
```
### Tidy the Data: Love on the Spectrum
Here, we will tidy the dataset by first reading in the files to Love on the Spectrum and Love is Blind.
```{r love_on_the_spectrum-read-files}
love_on_the_spectrum_files <-
  readtext(file = "../data/original/love_on_the_spectrum/*.srt",
           verbosity = 0) # suppresses warnings
```

```{r}
love_on_the_spectrum_files
```
Here, we are able to glimpse at the files in the dataset and see what we need to "tidy" in order to make the data more consistent. We see that there are periods dividing the title of the show, and then we see that there are letters (S and E) attached to the season number and episode number which is used to help identify which is which. For our purposes, we will have columns for each, so we do not need the defining S and E in our dataset. We also see that the files are .srt files, so we must also get rid of this as well.

```{r love_on_the_spectrum-metadata-clean-columns}
love_on_the_spectrum_files_separate <-
  love_on_the_spectrum_files %>%
  separate(col = doc_id, # column to break
           into = c("column_1", "column_2", "column_3", "column_4", "column_5"), # new columns created
           sep = "\\.",
           extra = "drop") # separator to break the doc_id column

love_on_the_spectrum_files_separate %>% # separated dataset
  select(-text) # do not show `text` column here
glimpse(love_on_the_spectrum_files_separate)
```
Our next goal is to separate the title of the file by using the separate() code and then dividing the original variable name `doc_id` into four columns. This allows us to get the full title, without the dividing periods now. Our next step is to divide column 5 into two columns: Season and Episode and then remove the S and E.

```{r love_on_the_spectrum-clean-columns-2}
love_on_the_spectrum_files_separate <-
  love_on_the_spectrum_files_separate %>%
  separate(col = column_5,
           into = c("Season", "Episode"),
           sep = "E")

love_on_the_spectrum_files_separate %>%
  select(-text)
```

```{r love_on_the_spectrum-unite-columns}
love_on_the_spectrum_files_unite <-
  love_on_the_spectrum_files_separate %>%
  unite(col = "Series", # new column name
        column_1:column_4, # columns to unite
        sep = " ") # separator to add between the column values
  
love_on_the_spectrum_files_unite %>% # united dataset
 select(-"text") # do not show the `text` column here
```
Here, we see the combination of columns 1 through 4 and we united them through the unite() function and we titled this column 'Series.'

```{r love_on_the_spectrum_meta}
love_on_the_spectrum_meta <-
  love_on_the_spectrum_files_unite %>%
  mutate(Season = str_remove(Season,
                             pattern = "S")) # remove the 'S' from the value in Season

glimpse(love_on_the_spectrum_meta) # preview full dataset
```
We now have renamed our columns to Series, Season, Episode, and Text. Our Series is titled "Love on the Spectrum" and we see the Season and Episode numbers no longer have the defining S and E.

### Curate Text: Love on the Spectrum
```{r}
love_on_the_spectrum_meta$text[1] %>% # subset the first observation of the text column
  str_trunc(width = 500) %>% # truncate the values to 500
  cat() # print the characters for inspection
```

Here, we see that the transcript has extra information than necessary, which will make it difficult to analyze. We must get rid of these time stamps, as well as the dashes at the start of what someone said, to make our data more consitent and concise.

```{r love_on_the_spectrum-clean-data}
love_on_the_spectrum_meta_lines <-
  love_on_the_spectrum_meta %>% # dataset with `text` column
  unnest_tokens(output = lines, # new column
                input = text, # input column
                token = "regex",
                pattern = "\\n", # split by new line anchor
                to_lower = FALSE) # do not lowercase the text

love_on_the_spectrum_meta_lines %>%# dataset
  slice_head(n = 10) # preview the first 10 observations
```

```{r love_on_the_spectrum-regular-expression}
love_on_the_spectrum_meta_lines %>%
  filter(str_detect(lines, "^\\d")) %>% # detect lines starting with a digit
  slice_sample(n = 10) # a random sample of 10 observations from the entire dataset
```
```{r love_on_the_spectrum-regular-expressions-to-remove}
love_on_the_spectrum_meta_lines_clean <-
  love_on_the_spectrum_meta_lines %>%
  filter(!str_detect(lines, "^\\d")) %>% # detect lines starting with a digit
  mutate(lines = str_remove(lines, "^-\\s")) %>% # remove leading '-' from each line
  filter(!str_detect(lines, "^\\[[a-z]")) %>% # remove lines starting with `[` before a lowercase letter
  mutate(lines = str_remove_all(lines, "\\[.+\\]")) %>% # remove cues inside of brackets (ex. [man])
  filter(!str_detect(lines,"^<.+?>.*")) %>% # remove lines starting with HTML tags
  mutate(lines = str_remove_all(lines, "<.+?>"))
# remove all HTML tags
```

```{r}
glimpse(love_on_the_spectrum_meta_lines_clean)
```
Here, we now see that we have gotten rid of digits that start the dialgue. We have also gotten rid of the dashes as well. 

```{r}
love_on_the_spectrum_curated <-
  love_on_the_spectrum_meta_lines_clean %>%
  group_by(Series, Season, Episode) %>% # grouping
  summarise(Dialogue = str_flatten(lines, collapse = " ")) %>% # collapse lines single observations for each series, season, episode combination
  ungroup() %>% # remove grouping attributes
  mutate(Dialogue = str_trim(Dialogue, side = "both")) # trim any leading or trailing whitespace from the united/flattened lines in dialogue
```
```{r}
love_on_the_spectrum_curated %>%
  mutate(Dialogue = str_trunc(Dialogue, 200)) 
```

We will now tidy the dataset for our Love is Blind data by repeating the same steps above.

### Tidy the Data: Love is Blind
```{r love_is_blind-read-files}
love_is_blind_files <-
  readtext(file = "../data/original/love_is_blind/*.srt",
           verbosity = 0) # suppresses warnings
glimpse(love_is_blind_files) # preview the structure of the dataset}

```
We see that this dataset is structured very similarly. We see our `doc_id` variable consists of the title of the series, the season number, the episode number, and extra information that we need to get rid of to make the dataset comparable with our Love on the Spectrum data.

```{r love_is_blind-metadata-clean-columns}
love_is_blind_files_separate <-
  love_is_blind_files %>%
  separate(col = doc_id, # column to break
           into = c("column_1", "column_2", "column_3", "column_4", "Episode Title"), # new columns created
           sep = "\\.",
           extra = "drop") # separator to break the doc_id column

love_is_blind_files_separate %>% # separated dataset
  select(-text) # do not show `text` column here
glimpse(love_is_blind_files_separate)

```

```{r love_is_blind-clean-columns-2}
love_is_blind_files_separate <-
  love_is_blind_files_separate %>%
  separate(col = column_4,
           into = c("Season", "Episode"),
           sep = "E")

love_is_blind_files_separate %>%
  select(-text)
```

```{r love_is_blind-unite-columns}
love_is_blind_files_unite <-
  love_is_blind_files_separate %>%
  unite(col = "Series", # new column name
        column_1:column_3, # columns to unite
        sep = " ") # separator to add between the column values
  
love_is_blind_files_unite %>% # united dataset
 select(-"text") # do not show the `text` column here
```
Here, after separating our columns, we unite the columns that correspond with one another; therefore, we will combine columns 1 through 3 and redefine this variable as "Series". We see that this dataset has an extra variable, "Episode Title". This information is not necessary for our analysis, so we can remove this variable so that the structure of the two datasets are the same.

```{r love_is_blind_meta}
love_is_blind_meta <-
  love_is_blind_files_unite %>%
  mutate(Season = str_remove(Season,
                             pattern = "S")) # remove the 'S' from the value in Season

glimpse(love_is_blind_meta) # preview full dataset}
```

### Tidy the Dataset: Love is Blind
```{r}
love_is_blind_meta$text[1] %>% # subset the first observation of the text column
  str_trunc(width = 500) %>% # truncate the values to 500
  cat() # print the characters for inspection
```

```{r love_is_blind-clean-data}
love_is_blind_meta_lines <-
  love_is_blind_meta %>% # dataset with `text` column
  unnest_tokens(output = Dialogue, # new column
                input = text, # input column
                token = "regex",
                pattern = "\\n", # split by new line anchor
                to_lower = FALSE) # do not lowercase the text

love_is_blind_meta_lines %>%# dataset
  slice_head(n = 10) # preview the first 10 observations}

```

```{r love_is_blind-regular-expressions-to-remove}
love_is_blind_meta_lines_clean <-
  love_is_blind_meta_lines %>%
  filter(!str_detect(Dialogue, "^\\d")) %>% # detect lines starting with a digit
  mutate(lines = str_remove(Dialogue, "^-\\s")) %>% # remove leading '-' from each line
  filter(!str_detect(Dialogue, "^\\[[a-z]")) %>% # remove lines starting with `[` before a lowercase letter
  mutate(lines = str_remove_all(Dialogue, "\\[.+\\]")) %>% # remove cues inside of brackets (ex. [man])
  filter(!str_detect(Dialogue,"^<.+?>.*")) %>% # remove lines starting with HTML tags
  mutate(lines = str_remove_all(Dialogue, "<.+?>"))
# remove all HTML tags}
```

```{r}
glimpse(love_is_blind_meta_lines_clean)
```
We have now gotten rid of the numbers and characters that existed in the "Dialogue".

```{r}
love_is_blind_curated <-
  love_is_blind_meta_lines_clean %>%
  group_by(Series, Season, Episode) %>% # grouping
  summarise(Dialogue = str_flatten(lines, collapse = " ")) %>% # collapse lines single observations for each series, season, episode combination
  ungroup() %>% # remove grouping attributes
  mutate(Dialogue = str_trim(Dialogue, side = "both")) # trim any leading or trailing whitespace from the united/flattened lines in dialogue

glimpse(love_is_blind_curated)
```

## Finalize
Our next step is to write the edited data by using the write_csv() code. We want to put our datasets in the `data/derived/` folder and from there, we want to put them in their respective folders. I recommend that you create the file folders for the two datasets in the `data/derived` folder so they do not get confused with one another. 

```{r love_on_the_spectrum-write-to-disk}
fs::dir_create(path = "../data/derived/love_on_the_spectrum/")
write_csv(love_on_the_spectrum_curated, # curated dataset
          file = "../data/derived/love_on_the_spectrum/love_on_the_spectrum_curated.csv")
```

```{r love_on_the_spectrum-create-dictionary, eval=FALSE}
data_dic_starter <- function(data, file_path) {
  # Function:
  # Creates a .csv file with the basic information
  # to document a curated dataset
  
  tibble(variable_name = names(data), # column with existing variable names
         name = " ", # column for human-readable names
         description = " ") %>%
    write_csv(file = file_path) # write to disk
} %>%

data_dic_starter(data = love_on_the_spectrum_curated, # curated dataset
                 file_path = "../data/derived/love_on_the_spectrum/love_on_the_spectrum_curated_data_dictionary.csv") 
```

```{r love_is_blind-write-to-disk}
fs::dir_create(path = "../data/derived/love_is_blind/")

write_csv(love_is_blind_curated, # curated dataset
          file = "../data/derived/love_is_blind/love_is_blind_curated.csv")
```

```{r love_is_blind-create-dictionary}
data_dic_starter <- function(data, file_path) {
  # Function:
  # Creates a .csv file with the basic information
  # to document a curated dataset
  
  tibble(variable_name = names(data), # column with existing variable names
         name = " ", # column for human-readable names
         description = " ") %>%
    write_csv(file = file_path) # write to disk
} %>%

data_dic_starter(data = love_is_blind_curated, # curated dataset
                 file_path = "../data/derived/love_is_blind/love_is_blind_curated_dictionary.csv")
```

### Log
The results of this script is our original dataset that we made edits to, which is now the derived dataset (since we didn't want to make edits to the original data). We get clean datasets (columns and rows that are better organized) for both Love on the Spectrum and Love is Blind so we are able to analyze the data easier.


### Session

<details><summary>View session information</summary>

```{r, child="_session-info.Rmd"}
```

</details>

## References
